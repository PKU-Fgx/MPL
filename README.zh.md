<p align="center">
    <br>
    <img src="assets/MPL-Logo.png" style="height: 250px;">
    <br>
    <h2 align="center">MPL: Multiple Programming Languages with Large Language Models for Information Extraction</h2>
    <hr>

<p align="center">
    <a href=""><img alt="GitHub license" src="https://img.shields.io/github/license/PKU-Fgx/transformers"></a>
    <a href="https://huggingface.co/collections/pku-fanggx/mpl-682c3bc6135458f10802720b"><img alt="Pretrained Models" src="https://img.shields.io/badge/ğŸ¤—HuggingFace-Pretrained Models-green"></a>
    <a href=""><img alt="Paper" src="https://img.shields.io/badge/ğŸ“–-Paper-orange"></a>
    <br>
</p>

<p align="justify">
We present<i> MPL: Multiple Programming Languages with Large Language Models for Information Extraction</i>. Recent advances in information extraction (IE) have explored the use of code-style prompts to improve structured output generation. This approach leverages the inherent structure of programming languages (PLs), which are often more precise and organized than natural language. While most existing work focuses on Python as the primary PL for simulation and fine-tuning, our framework MPL extends this paradigm by incorporating multiple widely-used programming languages , such as C++, Java, and Python, into the supervised fine-tuning (SFT) process. This allows the model to learn cross-language structural patterns that enhance IE performance. To further improve the code-style simulation, we introduce a novel function-prompt with virtual running , enabling more effective and efficient generation of structured outputs. This repository contains the implementation, training scripts, and evaluation tools for MPL. Please refer to the supplementary materials for more details and trained models.

- ğŸ“– Paper: [MPL: Multiple Programming Languages with Large Language Models for Information Extraction]()
</p>

<p align="center">
<img src="assets/main.png">
</p>

## ğŸ—ï¸ Repo Structure

```text
project/
â”œâ”€â”€ dataPreparation/          # æ•°æ®é¢„å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ Formatted/            # æ ¼å¼åŒ–åæ•°æ®è¾“å‡º
â”‚   â”œâ”€â”€ Raw/                  # åŸå§‹æ•°æ®ä¸ç›¸å…³å¤„ç†
â”‚   â”‚   â”œâ”€â”€ EAE/
â”‚   â”‚   â”œâ”€â”€ EE/
â”‚   â”‚   â”œâ”€â”€ NER/
â”‚   â”‚   â””â”€â”€ RE/
â”‚   â”œâ”€â”€ build.py              # å°†åŸå§‹æ„å»ºæˆæ ¼å¼åŒ–åçš„æ•°æ®
â”‚   â”œâ”€â”€ prompt.py             # IE æ•°æ®è½¬æ¢æˆ Code å½¢å¼çš„ Format Prompt
â”‚   â””â”€â”€ generate_datasets.ipynb  # ç”Ÿæˆç”¨äºè®­ç»ƒçš„å®Œæ•´æ•°æ®é›†
â”œâ”€â”€ train/                    # è®­ç»ƒç›¸å…³ä»£ç 
â”‚   â”œâ”€â”€ scripts/              # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ open_instruct/        # è®­ç»ƒæ ¸å¿ƒä»£ç 
â”‚   â””â”€â”€ run_mpl.sh            # å…¥å£è„šæœ¬
â”œâ”€â”€ evaluation/               # è¯„ä¼°æ¨¡å—
â””â”€â”€ dataTrain/                # è®­ç»ƒæ•°æ®å­˜å‚¨
```

## ğŸ“¥ Installation

1. å…‹éš†ä»“åº“ï¼š
```bash
git clone [repository_url]
cd [repository_name]
```

2. å®‰è£…ä¾èµ–ï¼š
```bash
# Environment setup
conda create -n MPL python=3.12 -y
conda activate MPL

# install dependencies
pip install -r requirements.txt
```

## ğŸ‹ï¸ è®­ç»ƒæ­¥éª¤

### 1. æ•°æ®é¢„å¤„ç†

1. è·å–åŸå§‹æ•°æ®é›†

    | Task | Dataset | Link | Label Explanations | Domain |
    |------|---------|------|--------------------|--------|
    | NER | ACE05 | [ACE 2005](https://catalog.ldc.upenn.edu/LDC2006T06 ) | âœ… | News |
    | NER | BC5CDR | [tner/bc5cdr](https://huggingface.co/datasets/tner/bc5cdr) | âŒ | Biomedical |
    | NER | CoNLL03 | [conll2003](https://www.clips.uantwerpen.be/conll2003/ner/) | âŒ | News |
    | NER | DIANN | [diann-sentences-english](https://huggingface.co/datasets/ferrazzipietro/diann-sentences-english) | âŒ | Biomedical |
    | NER | NCBID | [ncbi-disease](https://huggingface.co/datasets/nr2n23/ncbi-disease-sequence-classification) | âŒ | Biomedical |
    | NER | OntoNotes5* | [OntoNotes 5.0](https://www.ldc.upenn.edu/) | âŒ | News |
    | NER | WNUT2017 | [tner/wnut2017](https://huggingface.co/datasets/tner/wnut2017) | âŒ | News |
    | RE | ACE05 | [ACE 2005](https://catalog.ldc.upenn.edu/LDC2006T06) | âœ… | News |
    | RE | CoNLL04 | [DFKI-SLT/conll04](DFKI-SLT/conll04) | âŒ | News |
    | EAE | ACE05 | [ACE 2005](https://catalog.ldc.upenn.edu/LDC2006T06 ) | âœ… | News |
    | EAE | RAMS | [RAMS](https://nlp.jhu.edu/rams/) | âŒ | News |
    | EE | ACE05 | [ACE 2005](https://catalog.ldc.upenn.edu/LDC2006T06) | âœ… | News |

    - å…¶ä¸­ï¼Œéƒ¨åˆ†æ•°æ®é›†å¦‚ ACE05 ä¼šè‡ªå¸¦æ ‡ç­¾è§£é‡Šï¼Œä½†æ˜¯å…¶ä½™æ•°æ®é›†ä¸åŒ…å«æ ‡ç­¾è§£é‡Šï¼Œéœ€è¦é€šè¿‡ AI è‡ªåŠ¨ç”Ÿæˆï¼Œæˆ‘ä»¬åœ¨ Repo çš„ `dataPreparation/Raw/<TASK>` ä¸­æä¾›äº†ä¸€ä¸ªè§£é‡Šçš„ç‰ˆæœ¬ã€‚

    - å¦å¤–ï¼Œä¸ºäº†ä¿æŒå¯æ¯”è¾ƒæ€§ä»¥åŠå¢åŠ è®­ç»ƒæ•ˆç‡ï¼ŒOntoNotes5 æ•°æ®é›†æˆ‘ä»¬ä»ä¸­é‡‡æ ·äº† 30k æ¡ç›®æ•°æ®ç”¨äºè®­ç»ƒã€‚

    - åŸå§‹æ•°æ®å­˜æ”¾åœ¨ `dataPreparation/Raw/<TASK>` ç›®å½•ä¸‹ï¼Œæ¯ä¸ªä»»åŠ¡ç›®å½•éœ€åŒ…å«ï¼š
        - `label_exp.json`: æ ‡ç­¾å®šä¹‰ä¸è§£é‡Š
        - `label_map.json`: æ ‡ç­¾æ˜ å°„
        - `train.json`: è®­ç»ƒæ•°æ®
        - `dev.json`: éªŒè¯é›†æ•°æ®
        - `test.json`: æµ‹è¯•æ•°æ®

2. å°†åŸå§‹æ•°æ®é›†å¤„ç†åˆ°ä¸­é—´æ ¼å¼

    - ç”±äºåŸå§‹æ•°æ®çš„æ ¼å¼å¤šç§å¤šæ ·ï¼Œæˆ‘ä»¬åœ¨ `dataPreparation/Raw/<TASK>/trans_<TASK>.py` ä¸­æä¾›äº†å°†åŸå§‹æ ¼å¼æ•°æ®è½¬æ¢æˆä¸­é—´æ ¼å¼çš„å‚è€ƒä»£ç ï¼Œç„¶åä¸ºäº†å°†æ ‡ç­¾æ ¼å¼æ”¹ä¸ºç»Ÿä¸€ï¼Œæˆ‘ä»¬åœ¨ `dataPreparation/Raw/<TASK>/reformat.py` ä¸­æä¾›äº†å°†æ ‡ç­¾è¿›è¡Œæ ¼å¼åŒ–ç»Ÿä¸€çš„å‚è€ƒä»£ç ã€‚

    - ä¸ºäº†é¡ºåˆ©è¿›è¡Œä¸Šè¿°å·¥ä½œï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ªæ•°æ®é›†å‡†å¤‡ `label_exp.json` æ–‡ä»¶ï¼Œç”¨æ¥è¡¨ç¤º `{"label": "Explanation"}`ã€‚

    - å…·ä½“åœ°ï¼Œæ¯ç§æ•°æ®é›†çš„ä¸­é—´æ ¼å¼å‚è€ƒ `dataPreparation/README.md`ã€‚

3. å°†ä¸­é—´æ ¼å¼çš„æ•°æ®é›†è½¬æ¢æˆ CodeIE çš„å½¢å¼

    - ç»è¿‡ä¸Šè¿°æ­¥éª¤ä¹‹åï¼Œä¸­é—´æ ¼å¼æ•°æ®è¢«æ”¾ç½®åœ¨ `dataPreparation/Raw/<TASK>/<DATASET>/<SPLIT>.json` ä¹‹ä¸­ï¼Œå¯ä»¥é€šè¿‡ `dataPreparation/build.py` ç”Ÿæˆ CodeIE å½¢å¼çš„æ•°æ®é›†ï¼Œç”Ÿæˆåçš„æ•°æ®æ”¾ç½®äº `dataPreparation/Formatted` ä¹‹ä¸­ã€‚

4. ç”Ÿæˆç”¨äºè®­ç»ƒçš„è®­ç»ƒæ•°æ®

    - æœ€åé€šè¿‡ `dataPreparation/generate_datasets.ipynb` è„šæœ¬å°†è®­ç»ƒæ•°æ®æŒ‰ç…§ open-instruct çš„æ ¼å¼è¿›è¡Œæ•´åˆæ”¾ç½®äº `dataTrain` æ–‡ä»¶å¤¹ä¹‹ä¸­ã€‚

### 2. æ¨¡å‹è®­ç»ƒ

æˆ‘ä»¬ä½¿ç”¨ [allenai/open-instruct](https://github.com/allenai/open-instruct) è¿›è¡Œå¾®è°ƒï¼Œè¯¦ç»†å†…å®¹è¯·å‚è€ƒ `train/run_mpl.sh`ã€`train/scripts/MPL_qlora.sh` ä»¥åŠ `train/scripts/run.sh` è„šæœ¬ä»¥è·å¾—æ›´å¤šä¿¡æ¯ã€‚

```bash
# ä½¿ç”¨ MPL è®­ç»ƒè„šæœ¬
bash train/run_mpl.sh
```

#### 2.1 Pretrained models
Meanwhile, we release MPL models based on [CodeLLaMa](https://huggingface.co/codellama) (7B, 13B). The models are available in the ğŸ¤—HuggingFace Hub.

| Model |                     ğŸ¤— HuggingFace Hub                     |
|-------|:---------------------------------------------------------:|
| MPL-7B |  [pku-fanggx/MPL-7B-Qlora](https://huggingface.co/pku-fanggx/MPL-7B-Qlora)  |
| MPL-13B | [pku-fanggx/MPL-13B-Qlora](https://huggingface.co/pku-fanggx/MPL-13B-Qlora) |

### 3. æ¨¡å‹è¯„ä¼°

æˆ‘ä»¬ä½¿ç”¨ [vllm-project/vllm](https://github.com/vllm-project/vllm) è¿›è¡Œæ¨ç†è¯„ä¼°ï¼Œè¯·å‚è€ƒ `evaluation/README.md` ä»¥è·å¾—æ›´å¤šä¿¡æ¯ã€‚

```bash
# ä½¿ç”¨ vLLM è¿›è¡Œè¯„ä¼°
python evaluation/eval_vllm.py --model_id <model_id> --base_model_path <base_model_path> --lan <language>

# è®¡ç®—è¯„ä¼°åˆ†æ•°
python evaluation/get_scores.py --model_id <model_id> --method <method>
```

## ğŸ“ Citation
```bibtex
```